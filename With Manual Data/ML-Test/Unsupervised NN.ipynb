{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from scipy.ndimage import convolve\n",
    "from sklearn import linear_model, datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccf_train_data = \"./data/2018_4_21_22_38_train.csv\"\n",
    "ccf_test_data = \"./data/2018_4_30_08_33_test.csv\"\n",
    "\n",
    "\n",
    "def load_data(filepath):\n",
    "    from numpy import genfromtxt\n",
    "\n",
    "    csv_data = genfromtxt(filepath, delimiter=\",\", skip_header=1)\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for d in csv_data:\n",
    "        data.append(d[:-1])\n",
    "        labels.append(d[-1])\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_labels = load_data(ccf_train_data)\n",
    "test_dataset, test_labels = load_data(ccf_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_train_lables = KMeans(n_clusters=2, init='k-means++', n_init=10, max_iter=300,).fit_predict(train_dataset)\n",
    "predicted_test_lables = KMeans(n_clusters=2, init='k-means++', n_init=10, max_iter=300,).fit_predict(test_dataset)\n",
    "\n",
    "#traning Set labels --> K Mean Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models we will use\n",
    "logistic = linear_model.LogisticRegression()\n",
    "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
    "\n",
    "classifier = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -112406.90, time = 0.47s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -218526.11, time = 0.80s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -324088.78, time = 0.82s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -429334.12, time = 0.81s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -534379.51, time = 0.82s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -639324.31, time = 0.84s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -744212.94, time = 0.84s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -849061.35, time = 0.86s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -953899.71, time = 0.85s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -1058729.22, time = 0.77s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -1163559.16, time = 0.85s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -1268390.41, time = 0.79s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -1373218.18, time = 0.87s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -1478050.29, time = 0.82s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -1582880.27, time = 0.86s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -1687713.32, time = 0.91s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -1792543.67, time = 0.85s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -1897372.30, time = 0.83s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -2002204.46, time = 0.85s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -2107032.38, time = 0.85s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #############################################################################\n",
    "# Training\n",
    "\n",
    "# Hyper-parameters. These were set by cross-validation,\n",
    "# using a GridSearchCV. Here we are not performing cross-validation to\n",
    "# save time.\n",
    "rbm.learning_rate = 0.06\n",
    "rbm.n_iter = 20\n",
    "# More components tend to give better prediction performance, but larger\n",
    "# fitting time\n",
    "rbm.n_components = 100\n",
    "logistic.C = 6000.0\n",
    "\n",
    "# Training RBM-Logistic Pipeline\n",
    "classifier.fit(train_dataset, predicted_train_lables)\n",
    "\n",
    "# Training Logistic regression\n",
    "logistic_classifier = linear_model.LogisticRegression(C = 100.0)\n",
    "logistic_classifier.fit(test_dataset, predicted_test_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic regression using RBM features:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.49      1.00      0.66     49405\n",
      "        1.0       0.00      0.00      0.00     50595\n",
      "\n",
      "avg / total       0.24      0.49      0.33    100000\n",
      "\n",
      "\n",
      "Logistic regression using raw pixel features:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.52      0.49      0.50     12141\n",
      "        1.0       0.51      0.55      0.53     11999\n",
      "\n",
      "avg / total       0.52      0.52      0.52     24140\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\dilshan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "\n",
    "print(\"Logistic regression using RBM features:\\n%s\\n\" % (metrics.classification_report(test_labels, classifier.predict(test_dataset))))\n",
    "\n",
    "print(\"Logistic regression using raw pixel features:\\n%s\\n\" % (metrics.classification_report(train_labels, logistic_classifier.predict(train_dataset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
